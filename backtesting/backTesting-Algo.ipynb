{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Aviral\\GITHUB\\Price-Prediction\\myenv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Aviral\\GITHUB\\Price-Prediction\\myenv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Aviral\\GITHUB\\Price-Prediction\\myenv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Aviral\\GITHUB\\Price-Prediction\\myenv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Aviral\\GITHUB\\Price-Prediction\\myenv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Aviral\\GITHUB\\Price-Prediction\\myenv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Aviral\\GITHUB\\Price-Prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23260/23260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 11ms/step - loss: 29133644.0000 - val_loss: 27892294.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m23260/23260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 11ms/step - loss: 25720322.0000 - val_loss: 26714006.0000\n",
      "Epoch 3/20\n",
      "\u001b[1m23260/23260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 10ms/step - loss: 25640202.0000 - val_loss: 25175744.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m23257/23260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 25535238.0000"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    return data\n",
    "\n",
    "# ARIMA model for linear patterns\n",
    "def fit_arima(data, order=(1, 1, 1)):\n",
    "    model = ARIMA(data, order=order)\n",
    "    arima_fit = model.fit()\n",
    "    return arima_fit\n",
    "\n",
    "# Prepare data for neural network\n",
    "def prepare_nn_data(residuals, original_data, future_steps=15):\n",
    "    residuals = residuals[~np.isnan(residuals)]  # Drop NaN residuals\n",
    "    X, y = [], []\n",
    "    for i in range(len(residuals) - future_steps):\n",
    "        X.append(residuals[i:i + future_steps])\n",
    "        y.append(original_data[i + future_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Build LSTM neural network\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, activation='relu', input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Predict single value (price)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Combine ARIMA and LSTM predictions\n",
    "def predict_hybrid(arima_fit, lstm_model, data, scaler, future_steps=15):\n",
    "    arima_forecast = arima_fit.forecast(steps=future_steps)[-1]  # ARIMA prediction\n",
    "    nn_input = data[-future_steps:]  # Last residuals for NN input\n",
    "    nn_input = scaler.transform(nn_input.reshape(-1, 1)).reshape(1, -1, 1)\n",
    "    nn_forecast = lstm_model.predict(nn_input)\n",
    "    return arima_forecast + scaler.inverse_transform(nn_forecast).flatten()[0]\n",
    "\n",
    "# Main workflow\n",
    "def main(file_path):\n",
    "    # Step 1: Load data\n",
    "    data = load_data(file_path)\n",
    "    close_prices = data['close']\n",
    "\n",
    "    # Step 2: Fit ARIMA\n",
    "    arima_fit = fit_arima(close_prices)\n",
    "\n",
    "    # Step 3: Extract ARIMA residuals\n",
    "    residuals = arima_fit.resid\n",
    "\n",
    "    # Step 4: Scale residuals for NN\n",
    "    scaler = MinMaxScaler()\n",
    "    residuals_scaled = scaler.fit_transform(residuals.values.reshape(-1, 1))\n",
    "\n",
    "    # Step 5: Prepare data for NN\n",
    "    X, y = prepare_nn_data(residuals_scaled, close_prices.values)\n",
    "\n",
    "    # Reshape X for LSTM input (samples, timesteps, features)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "    # Step 6: Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 7: Build and train LSTM model\n",
    "    lstm_model = build_lstm_model(X_train.shape[1:])\n",
    "    lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Step 8: Predict using hybrid model\n",
    "    hybrid_prediction = predict_hybrid(arima_fit, lstm_model, residuals.values, scaler)\n",
    "    print(f\"Hybrid Prediction for 15 minutes later: {hybrid_prediction}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'data/nifty2015-2025.csv'  # file path\n",
    "    main(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
